{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** до 27 ноября 2017, 23:59   \n",
    "**Штраф за опоздание:** -2 балла после 23:59  4 декабря, -4 балла после 23:59 11 декабря, -6 баллов после 23:59 18 декабря\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла   \n",
    "\n",
    "\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий в slack @alkhamush\n",
    "Необходимо в slack создать таск в приватный чат:   \n",
    "/todo Фамилия Имя *ссылка на гитхаб* @alkhamush   \n",
    "Пример:   \n",
    "/todo Ксения Стройкова https://github.com/stroykova/spheremailru/stroykova_hw1.ipynb @alkhamush   \n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Разбаловка:**   \n",
    "За задание можно получить 10 баллов. Для этого нужно следующее:\n",
    "1. Там, где написано \"Ваш код\", нужно реализовать метод или часть метода\n",
    "2. Там, где написано \"Что делает этот блок кода?\", нужно разобраться в блоке кода и в комментарии написать, что он делает    \n",
    "3. Добиться, чтобы в пункте \"Проверка скорости работы\" Ваша реализация работала чуть быстрее, чем у дерева из sklearn\n",
    "4. Добиться, чтобы в пункте \"Проверка качества работы\" Ваша реализация работала качественнее, чем у дерева из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy import optimize\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Функция обработки неправильных разбиений без эвристики (см. ниже функцию __fit_threshold)\n",
    "def simple_split(x, x_l, x_r):\n",
    "    return (x_l + x_r) / 2.0\n",
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2, max_depth=None, sufficient_share=1.0, criterion='gini', max_features=None,\n",
    "                 split_function=None):\n",
    "        self.tree = dict()\n",
    "        # min_samples_split - минимальное количество значений после разделения\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        if criterion == 'gini':\n",
    "            self.G_function = self.__gini\n",
    "        elif criterion == 'entropy':\n",
    "            self.G_function = self.__entropy\n",
    "        elif criterion == 'misclass':\n",
    "            self.G_function = self.__misclass\n",
    "        else:\n",
    "            print 'invalid criterion name'\n",
    "            raise\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature_ids = self.__get_feature_ids_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature_ids = self.__get_feature_ids_log2\n",
    "        elif max_features == None:\n",
    "            self.get_feature_ids = self.__get_feature_ids_N\n",
    "        else:\n",
    "            print 'invalid max_features name'\n",
    "            raise\n",
    "            \n",
    "        # Функция эврестической обработки разбиения выборки, когда по бокам одинаковые значения x\n",
    "        if split_function is None:\n",
    "            self.split_function = simple_split\n",
    "        else:\n",
    "            self.split_function = split_function\n",
    "    \n",
    "    # Делает массив долей из массива частот в делении\n",
    "    def __get_parts(self, l_c, l_s, r_c, r_s):\n",
    "        l_s = l_s.astype('float')\n",
    "        r_s = r_s.astype('float')\n",
    "        return l_c/l_s, r_c/r_s\n",
    "    \n",
    "    # Возвращает взвешенную неопределенность (|S_l|*Imp(S_l)+|S_r|*Imp(S_r)).\n",
    "    # Деление на |S| не нужно (=const в узле)\n",
    "    def __weight_impurity(self, l_s, impurity_l, l_r, impurity_r):\n",
    "        impurity_l = impurity_l.reshape(-1, 1)\n",
    "        impurity_r = impurity_r.reshape(-1, 1)\n",
    "        return l_s*impurity_l+l_r*impurity_r\n",
    "    \n",
    "    # l_c - количество элементов каждого класса слева\n",
    "    # l_s - размер левого класса\n",
    "    # Аналогично для r_c, r_s\n",
    "    def __gini(self, l_c, l_s, r_c, r_s):\n",
    "        l_p, r_p = self.__get_parts(l_c, l_s, r_c, r_s)\n",
    "        return self.__weight_impurity(l_s, 1-np.sum(l_p*l_p, axis=1), r_s, 1-np.sum(r_p*r_p, axis=1)) # Ваш код\n",
    "    \n",
    "    def __entropy(self, l_c, l_s, r_c, r_s):\n",
    "        l_p, r_p = self.__get_parts(l_c, l_s, r_c, r_s)\n",
    "        return self.__weight_impurity(l_s, -np.sum(l_p*np.log(l_p), axis=1),\n",
    "                                      r_s, -np.sum(r_p*np.log(r_p), axis=1)) # Ваш код \n",
    "\n",
    "    def __misclass(self, l_c, l_s, r_c, r_s):\n",
    "        l_p, r_p = self.__get_parts(l_c, l_s, r_c, r_s)\n",
    "        return self.__weight_impurity(l_s, 1-np.max(l_p, axis=1), r_s, 1-np.max(r_p, axis=1)) # Ваш код\n",
    "\n",
    "    def __get_feature_ids_sqrt(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:int(np.sqrt(n_feature))]# Ваш код\n",
    "        \n",
    "    def __get_feature_ids_log2(self, n_feature):\n",
    "        feature_ids = range(n_feature)\n",
    "        np.random.shuffle(feature_ids)\n",
    "        return feature_ids[0:int(np.log2(n_feature))]# Ваш код\n",
    "\n",
    "    def __get_feature_ids_N(self, n_feature):\n",
    "        return range(n_feature)# Ваш код\n",
    "    \n",
    "    def __sort_samples(self, x, y):\n",
    "        sorted_idx = x.argsort()\n",
    "        return x[sorted_idx], y[sorted_idx]\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        #print x[:, feature_id], threshold\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        #print left_mask\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "    \n",
    "    # x - значения количественного признака у объектов на входе\n",
    "    # y - соответствующие классы объектов на входе\n",
    "    def __find_threshold(self, x, y):\n",
    "        # Что делает этот блок кода?\n",
    "        # Сортирует полученные объекты по значению признака x\n",
    "        # Массив sorted_x - отсортированные значения признака, sorted_y - соответствующие классы\n",
    "        # class_number - количество различных классов среди полученных объектов\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        class_number = np.unique(y).shape[0]\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Рассчитывает индексы пороговых значений (где меняется класс объекта), которые будут рассматриваться в дереве\n",
    "        # Индексы - начала новых классов\n",
    "        # Первая строчка - гарантия того, что после любого разбиения в каждом классе будет\n",
    "        # min_samples_split значений (индексы разбиений не будут меньше self.min_samples_split + 1) - \"обрезание\"\n",
    "        # Вторая строчка - расчет индексов границ. splitted_sorted_y[:-1] != splitted_sorted_y[1:] - \n",
    "        # даст True, если предыдущее значение в массиве не совпадает со следующим\n",
    "        # where(...)[0] - дает номера этих индексов, +(self.min_samples_split + 1) - потому что было смещение\n",
    "        # в первой строчке\n",
    "        # Добавлена эвристика. Рассмотрим выборку\n",
    "        # sorted_x: 0 0 0 1 1 1\n",
    "        # sorted_y: 1 1 0 0 1 1\n",
    "        # Тогда при пороговых значениях 0 и 1 выборка якобы будет разделена на (1 1 ; 0 0 1 1) и (1 1 0 0 ; 1 1)\n",
    "        # (якобы - потому что в данном алгоритме деление привязано к порогам, а не к значениям), но это неправильно\n",
    "        # sorted_x: 6 6 7 7 8 8\n",
    "        # sorted_y: 1 1 1 0 0 0\n",
    "        # 7 - более-менее разумный threshold. Разные варианты условий с комментариями ниже.\n",
    "        splitted_sorted_y = sorted_y[self.min_samples_split:-self.min_samples_split]\n",
    "        r_border_ids = np.where(splitted_sorted_y[:-1] != splitted_sorted_y[1:])[0] + (self.min_samples_split + 1)\n",
    "        \n",
    "        # Не могут быть слева и справа одновременно минимальный или максимальный x - это не разделит выборку\n",
    "        #print \"SortedX\", sorted_x, \"max\", x.max(), \"min\", x.min()\n",
    "        #r_border_ids = r_border_ids[((sorted_x[r_border_ids-1] != x.min()) | (sorted_x[r_border_ids] != x.min())) &\n",
    "        #                            ((sorted_x[r_border_ids-1] != x.max()) | (sorted_x[r_border_ids] != x.max()))]\n",
    "        # Получилось плохо - очень глубокое дерево за счет того, что теряется порог 0.5 (например, в примере выше)\n",
    "        \n",
    "        #print \"RBI\", r_border_ids\n",
    "        #print \"SortedY\", sorted_y\n",
    "        \n",
    "        if len(r_border_ids) == 0:\n",
    "            return float('+inf'), None\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Определяет количество объектов каждого типа в каждом классе после деления, объекты \"обрезанные\" слева\n",
    "        # включаются в первый класс (с нулевым индексом)\n",
    "        # eq_el_count - количество объектов, находящихся между 2мя соседними рассматриваемыми границами\n",
    "        # без учета \"боковых\" объектов (гарантировавших min_samples_split)\n",
    "        # one_hot_code - указывает, какой класс был предыдущим на этой границе в виде one-hot encoding\n",
    "        # class_increments - таблица: границы\\классы с указанием количества объектов между границами (инициализация)\n",
    "        # class_increments - таблица: количество объектов каждого типа входит в классах (разделенных по границам)\n",
    "        # \"Обрезанные\" значения в начале включаются в первый класс\n",
    "        # Ошибка - в последней строчке sorted_y - исправлено\n",
    "        eq_el_count = r_border_ids - np.append([self.min_samples_split], r_border_ids[:-1])\n",
    "        one_hot_code = np.zeros((r_border_ids.shape[0], class_number))\n",
    "        one_hot_code[np.arange(r_border_ids.shape[0]), sorted_y[r_border_ids - 1]] = 1\n",
    "        class_increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        class_increments[0] = class_increments[0] + np.bincount(sorted_y[:self.min_samples_split], minlength=class_number)\n",
    "        \n",
    "        # Что делает этот блок кода?\n",
    "        # Рассчитывает параметры разбиений: количество объектов каждого класса в частях разбиения\n",
    "        # l_class_count - количество объектов каждого типа, остающихся слева при разбиении по каждой границе\n",
    "        # l_class_count - 2D массив (cout_borders, count_classes)\n",
    "        # r_class_count - аналогичный 2D массив, количество объектов, остающихся справа при разбиении по каждой границе\n",
    "        # l_sizes - размеры левых классов при разбиении по каждой границе - столбец\n",
    "        # r_sizes - аналогично для правых классов\n",
    "        l_class_count = np.cumsum(class_increments, axis=0)        \n",
    "        r_class_count = np.bincount(y) - l_class_count\n",
    "        l_sizes = r_border_ids.reshape(l_class_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        # Что делает этот блок кода?\n",
    "        # Выбирает оптимальное разбиение (соответствующее минимуму взвешенной меры неопределенности конечных классов -\n",
    "        # максимуму прироста информации). Взвешенная неопределенность берется без деления на |S| = const\n",
    "        # gs - мера неопределенности для всех разбиений\n",
    "        # idx - номер оптимального\n",
    "        gs = self.G_function(l_class_count, l_sizes, r_class_count, r_sizes)\n",
    "        #print gs.shape\n",
    "        idx = np.argmin(gs)\n",
    "        #print \"TH\", (sorted_x[r_border_ids-1]+sorted_x[r_border_ids])/2.0\n",
    "        #print \"GS\", gs, l_class_count, r_class_count\n",
    "    \n",
    "        # Что делает этот блок кода?\n",
    "        # Возвращает оптимальное разбиение: взвешенную энтропию при оптимальном разбиении,\n",
    "        # trashhold (среднее значение количественного признака до и после границы класса)\n",
    "        left_el_id = l_sizes[idx][0]\n",
    "        \n",
    "        # Функция split_function (правила обработки threshhold) вынесена за пределы класса, чтобы ее можно было поменять\n",
    "        # разбиения, когда по бокам одинаковые значения x\n",
    "        return gs[idx], self.split_function(sorted_x, sorted_x[left_el_id-1], sorted_x[left_el_id])\n",
    "    \n",
    "    # Создает лист\n",
    "    def __create_leaf(self, y):\n",
    "        probabilities = np.bincount(y, minlength=self.num_class)/float(len(y))\n",
    "        # В predict - node[1] - самый популярный класс\n",
    "        # node[2] - вероятности\n",
    "        return (self.LEAF_TYPE, probabilities.argmax(), probabilities)\n",
    "    \n",
    "    # Определяет, нужно создавать лист (тогда вернет 0) или вершину (тогда -1)\n",
    "    def __what_create(self, y):\n",
    "        max_part = np.bincount(y).max()/len(y)\n",
    "        return -1 if (max_part < self.sufficient_share) else 0\n",
    "    \n",
    "    # Мы не различаем количественные и категориальные признаки\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        # Что такое pred_f? Что такое sufficient_share - максимальная доля?\n",
    "        # Ваш код\n",
    "        # Необходимо использовать следующее:\n",
    "        # self.LEAF_TYPE +\n",
    "        # self.NON_LEAF_TYPE +\n",
    "\n",
    "        # self.tree +\n",
    "        # self.max_depth +\n",
    "        # self.sufficient_share (?)\n",
    "        # self.min_samples_split +\n",
    "\n",
    "        # self.get_feature_ids +\n",
    "        # self.__find_threshold +\n",
    "        # self.__div_samples +\n",
    "        # self.__fit_node +\n",
    "        \n",
    "        # Пока будем считать pred_f = 0 => это нужно сделать листом\n",
    "        #print \"start\", pred_f, len(y)\n",
    "        # Пустой узел не создается\n",
    "        if (len(y) == 0):\n",
    "            return\n",
    "        if (pred_f == 0) or (len(y) <= self.min_samples_split*2):\n",
    "            self.tree[node_id] = self.__create_leaf(y)\n",
    "            return\n",
    "        if (depth == self.max_depth) and not (depth is None):\n",
    "            self.tree[node_id] = self.__create_leaf(y)\n",
    "            return\n",
    "        \n",
    "        features_for_node = self.get_feature_ids(x.shape[1])\n",
    "        possible_conditions = list() #node - tuple: (feature_id, threshold)\n",
    "        impurities = list()\n",
    "        for feature in features_for_node:\n",
    "            #print \"Feature\", feature\n",
    "            impurity, threshold = self.__find_threshold(x[:, feature], y)\n",
    "            #print \"I - T\", impurity, threshold\n",
    "            possible_conditions.append((feature, threshold))\n",
    "            impurities.append(impurity)\n",
    "        \n",
    "        result_feature, result_threshold = possible_conditions[np.array(impurities).argmin()]\n",
    "        #print \"RF, RT\", result_feature, result_threshold\n",
    "        splitted_observations = self.__div_samples(x, y, result_feature, result_threshold)\n",
    "        #print splitted_observations\n",
    "        \n",
    "        # Если при разбиении образовался пустой класс, то мы работаем с листом\n",
    "        if (len(splitted_observations[0]) == 0) or (len(splitted_observations[1]) == 0):\n",
    "            self.tree[node_id] = self.__create_leaf(y)\n",
    "            return\n",
    "        #print \"EMPTY\", has_empty_class\n",
    "        \n",
    "        self.tree[node_id] = (self.NON_LEAF_TYPE, result_feature, result_threshold)\n",
    "        self.__fit_node(splitted_observations[0], splitted_observations[2], node_id*2 + 1, depth+1,\n",
    "                        self.__what_create(splitted_observations[2]))\n",
    "        self.__fit_node(splitted_observations[1], splitted_observations[3], node_id*2 + 2, depth+1,\n",
    "                        self.__what_create(splitted_observations[3]))\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.__fit_node(x, y, 0, 0) \n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        #print x\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            #print node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def __predict_probs(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_probs(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_probs(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[2]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "    \n",
    "    def predict_probs(self, X):\n",
    "        return np.array([self.__predict_probs(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Эвристика. Если sorted_x[left_el_id-1] = sorted_x[left_el_id] = max(x), \n",
    "# то, вероятно, \"хорошее\" разбиение отсекает максимальные значения x. Попробуем это указать (для мин - аналогично)\n",
    "# Возвращет полусумму x1 и x2 в общем случае, (x1+pre_max_x)/2, если x1=x2=max, (x1+pre_min_x)/2, если x1=x2=min\n",
    "# Для обработки предполагаемых разбиений, которые реально не разбивают группу\n",
    "def evristic_split(x, x_l, x_r):\n",
    "    # Получилось лучше, чем с фильтрацией массива r_border_ids, но все равно медленно - 5 сек.\n",
    "    uniq_x = np.unique(x)\n",
    "    if len(uniq_x) == 1:\n",
    "        return (x_l + x_r) / 2.0\n",
    "    if (x_l == uniq_x[0] and x_r == uniq_x[0]):\n",
    "        return (uniq_x[0] + uniq_x[1]) / 2.0\n",
    "    if (x_l == uniq_x[-1] and x_r == uniq_x[-1]):\n",
    "        return (uniq_x[-1] + uniq_x[-2]) / 2.0\n",
    "    return (x_l + x_r) / 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeriousDlqin2yrs</th>\n",
       "      <th>RevolvingUtilizationOfUnsecuredLines</th>\n",
       "      <th>age</th>\n",
       "      <th>NumberOfTime30-59DaysPastDueNotWorse</th>\n",
       "      <th>DebtRatio</th>\n",
       "      <th>MonthlyIncome</th>\n",
       "      <th>NumberOfOpenCreditLinesAndLoans</th>\n",
       "      <th>NumberOfTimes90DaysLate</th>\n",
       "      <th>NumberRealEstateLoansOrLines</th>\n",
       "      <th>NumberOfTime60-89DaysPastDueNotWorse</th>\n",
       "      <th>NumberOfDependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.766127</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>0.802982</td>\n",
       "      <td>9120.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.957151</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>0.121876</td>\n",
       "      <td>2600.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.658180</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085113</td>\n",
       "      <td>3042.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.233810</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.036050</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0.907239</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>0.024926</td>\n",
       "      <td>63588.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SeriousDlqin2yrs  RevolvingUtilizationOfUnsecuredLines  age  \\\n",
       "1                 1                              0.766127   45   \n",
       "2                 0                              0.957151   40   \n",
       "3                 0                              0.658180   38   \n",
       "4                 0                              0.233810   30   \n",
       "5                 0                              0.907239   49   \n",
       "\n",
       "   NumberOfTime30-59DaysPastDueNotWorse  DebtRatio  MonthlyIncome  \\\n",
       "1                                     2   0.802982         9120.0   \n",
       "2                                     0   0.121876         2600.0   \n",
       "3                                     1   0.085113         3042.0   \n",
       "4                                     0   0.036050         3300.0   \n",
       "5                                     1   0.024926        63588.0   \n",
       "\n",
       "   NumberOfOpenCreditLinesAndLoans  NumberOfTimes90DaysLate  \\\n",
       "1                               13                        0   \n",
       "2                                4                        0   \n",
       "3                                2                        1   \n",
       "4                                5                        0   \n",
       "5                                7                        0   \n",
       "\n",
       "   NumberRealEstateLoansOrLines  NumberOfTime60-89DaysPastDueNotWorse  \\\n",
       "1                             6                                     0   \n",
       "2                             0                                     0   \n",
       "3                             0                                     0   \n",
       "4                             0                                     0   \n",
       "5                             1                                     0   \n",
       "\n",
       "   NumberOfDependents  \n",
       "1                 2.0  \n",
       "2                 1.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "5                 0.0  "
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./cs-training.csv', sep=',').dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = df.as_matrix(columns=df.columns[1:])\n",
    "y = df.as_matrix(columns=df.columns[:1])\n",
    "y = y.reshape(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "my_clf_evr = MyDecisionTreeClassifier(min_samples_split=2, split_function=evristic_split)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ..., 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print y\n",
    "my_clf.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка скорости работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без эвристики\n",
      "0.422000169754\n",
      "351\n",
      "0.952999830246\n"
     ]
    }
   ],
   "source": [
    "print \"Без эвристики\"\n",
    "t1 = time()\n",
    "my_clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "print len(my_clf.tree)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, для алгоритма без эвристики задание по времени выполнено. Проверим точность.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "С эвристикой\n",
      "4.6099998951\n",
      "4957\n",
      "0.969000101089\n"
     ]
    }
   ],
   "source": [
    "# Быстрее, чем sklearn - нужно отключить эврестическую обработку \"неправильных\" разрезаний выборки - см. выше\n",
    "print \"С эвристикой\"\n",
    "t1 = time()\n",
    "my_clf_evr.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)\n",
    "print len(my_clf_evr.tree)\n",
    "\n",
    "t1 = time()\n",
    "clf.fit(x, y)\n",
    "t2 = time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверка качества работы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Без эвристики\n",
      "Len_tree 533\n",
      "0.931778498379\n",
      "Len_tree 679\n",
      "0.932152656523\n",
      "Len_tree 2215\n",
      "0.928369501954\n",
      "Len_tree 2955\n",
      "0.933108838447\n",
      "Len_tree 3365\n",
      "0.932815033468\n"
     ]
    }
   ],
   "source": [
    "print \"Без эвристики\"\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf.fit(X_train, y_train)\n",
    "    print \"Len_tree\", len(my_clf.tree)\n",
    "    print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C эвристикой\n",
      "Len_tree 9063\n",
      "0.926082979962\n",
      "Len_tree 12355\n",
      "0.925043651783\n",
      "Len_tree 14847\n",
      "0.923962750478\n",
      "Len_tree 18787\n",
      "0.9229234223\n",
      "Len_tree 22267\n",
      "0.924666361784\n"
     ]
    }
   ],
   "source": [
    "print \"C эвристикой\"\n",
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    my_clf_evr.fit(X_train, y_train)\n",
    "    print \"Len_tree\", len(my_clf_evr.tree)\n",
    "    print(accuracy_score(y_pred=my_clf_evr.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.893032343893\n",
      "0.893032343893\n",
      "0.892533466367\n",
      "0.889831213104\n",
      "0.891115453374\n"
     ]
    }
   ],
   "source": [
    "for train, test in gkf.split(x, y):\n",
    "    X_train, y_train = x[train], y[train]\n",
    "    X_test, y_test = x[test], y[test]\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, на данном наборе данных алгоритм без эвристики работает лучше и удовлетворяет поставленным условиям.  \n",
    "Однако, возможно, в другом случае будет лучше работать алгоритм с эвристикой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
